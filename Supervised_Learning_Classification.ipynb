{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Libraries**"
      ],
      "metadata": {
        "id": "wPR5OUeSda-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Uo2B1Q9HdYDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing data**"
      ],
      "metadata": {
        "id": "Fzzg83hieJws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Import Dataset"
      ],
      "metadata": {
        "id": "S-9LhfNxdg9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fileName = 'data.xlsx'\n",
        "\n",
        "try:\n",
        " # Confirm file exists.\n",
        " sheetValues = pd.read_excel(fileName)\n",
        " print(' .. successful parsing of file:', fileName)\n",
        " print(\"Column headings:\")\n",
        " print(sheetValues.columns)\n",
        "except FileNotFoundError:\n",
        " print(FileNotFoundError)\n",
        "\n",
        "# Fisrt get only the numeric values; i.e. ignore last two columns, and convert it to ndarray\n",
        "inputData = sheetValues[sheetValues.columns[:-2]].values\n",
        "# Labels\n",
        "outputData = sheetValues[sheetValues.columns[-2]]\n",
        "\n",
        "print(' .. we have', inputData.shape[0], 'available paradigms.')\n",
        "print(' .. each paradigm has', inputData.shape[1], 'features')\n",
        "print(' ... the distribution for the available class lebels is:')\n",
        "\n",
        "for classIdx in range(0, len(np.unique(outputData))):\n",
        "  tmpCount = sum(outputData == classIdx)\n",
        "  tmpPercentage = tmpCount/len(outputData)\n",
        "  print(' .. class', str(classIdx), 'has', str(tmpCount), 'instances', '(','{:.2f}'.format(tmpPercentage), '%)')"
      ],
      "metadata": {
        "id": "7eywHsVxdfMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Split to training and test set"
      ],
      "metadata": {
        "id": "6YrsMAtkdrY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Split dataset sto training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputData, outputData, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "KsgqfvKkd9X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Normalize data points"
      ],
      "metadata": {
        "id": "dzZXzLcAeDVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize data\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "83oTxcvMeD3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualization: TSNE Projection of the dataset**"
      ],
      "metadata": {
        "id": "ofUII8Y4eQW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, verbose=1, random_state=0)\n",
        "z = tsne.fit_transform(inputData)\n",
        "df = pd.DataFrame()\n",
        "df[\"y\"] = outputData\n",
        "df[\"comp-1\"] = z[:,0]\n",
        "df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                palette=sns.color_palette(\"bright\", 2),\n",
        "                data=df).set(title=\"Data in T-SNE projection\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1zCBBq6eeiwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "525gbEKbe4Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "\n",
        "clf = DecisionTreeClassifier(max_depth=6, random_state=0)\n",
        "clf.fit(X_train, y_train) #fit the model using the training data\n",
        "#now check for both train and test data, how well the model learned the patterns\n",
        "y_pred_train = clf.predict(X_train)\n",
        "y_pred_test = clf.predict(X_test)\n",
        "\n",
        "#Make confusion matrix to define tp, tn, fp, fn\n",
        "confMatrix = confusion_matrix(y_test, y_pred_test)\n",
        "cmDisplay = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = [\"1\", \"2\"])\n",
        "cmDisplay.plot()\n",
        "plt.show()\n",
        "\n",
        "#Calculate the scores\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "pre_train = precision_score(y_train, y_pred_train, average='macro')\n",
        "pre_test = precision_score(y_test, y_pred_test, average='macro')\n",
        "rec_train = recall_score(y_train, y_pred_train, average='macro')\n",
        "rec_test = recall_score(y_test, y_pred_test, average='macro')\n",
        "f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
        "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
        "\n",
        "#Print the scores\n",
        "print('Accuracy scores of Decision Tree classifier are:',\n",
        " 'train: {:.2f}'.format(acc_train), 'and test:{:.2f}.'.format(acc_test))\n",
        "print('Precision scores of Decision Tree classifier are:',\n",
        " 'train: {:.2f}'.format(pre_train), 'and test:{:.2f}.'.format(pre_test))\n",
        "print('Recall scores of Decision Tree classifier are:',\n",
        " 'train: {:.2f}'.format(rec_train), 'and test:{:.2f}.'.format(rec_test))\n",
        "print('F1 scores of Decision Tree classifier are:',\n",
        " 'train: {:.2f}'.format(f1_train), 'and test: {:.2f}.'.format(f1_test))\n",
        "\n",
        "#Decision Tree Graph\n",
        "plt.figure(figsize=(15,10))\n",
        "_ = tree.plot_tree(clf, filled=True, feature_names=sheetValues.columns[:-2], max_depth =3,\n",
        "                   class_names = [\"1\",\"2\"], proportion=True,  fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xJHws4ncfB8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**k-Nearest Neighbors**"
      ],
      "metadata": {
        "id": "jR9dmZSzfLzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors = 7)\n",
        "knn.fit(X_train, y_train) #fit the model using the training data\n",
        "#now check for both train and test data, how well the model learned the patterns\n",
        "y_pred_train = knn.predict(X_train)\n",
        "y_pred_test = knn.predict(X_test)\n",
        "\n",
        "#Make confusion matrix to define tp, tn, fp, fn\n",
        "confMatrix = confusion_matrix(y_test, y_pred_test)\n",
        "cmDisplay = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = [\"1\", \"2\"])\n",
        "cmDisplay.plot()\n",
        "plt.show()\n",
        "\n",
        "#Calculate the scores\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "pre_train = precision_score(y_train, y_pred_train, average='macro')\n",
        "pre_test = precision_score(y_test, y_pred_test, average='macro')\n",
        "rec_train = recall_score(y_train, y_pred_train, average='macro')\n",
        "rec_test = recall_score(y_test, y_pred_test, average='macro')\n",
        "f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
        "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
        "\n",
        "#Print the scores\n",
        "print('Accuracy scores of k-Nearest Neighbors classifier are:',\n",
        " 'train: {:.2f}'.format(acc_train), 'and test:{:.2f}.'.format(acc_test))\n",
        "print('Precision scores of k-Nearest Neighbors classifier are:',\n",
        " 'train: {:.2f}'.format(pre_train), 'and test:{:.2f}.'.format(pre_test))\n",
        "print('Recall scores of k-Nearest Neighbors classifier are:',\n",
        " 'train: {:.2f}'.format(rec_train), 'and test:{:.2f}.'.format(rec_test))\n",
        "print('F1 scores of k-Nearest Neighbors classifier are:',\n",
        " 'train: {:.2f}'.format(f1_train), 'and test: {:.2f}.'.format(f1_test))"
      ],
      "metadata": {
        "id": "ORpfUynDfSO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Discriminant Analysis**"
      ],
      "metadata": {
        "id": "GVjPJeTDfVDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(X_train, y_train) #fit the model using the training data\n",
        "#now check for both train and test data, how well the model learned the patterns\n",
        "y_pred_train = lda.predict(X_train)\n",
        "y_pred_test = lda.predict(X_test)\n",
        "\n",
        "#Make confusion matrix to define tp, tn, fp, fn\n",
        "confMatrix = confusion_matrix(y_test, y_pred_test)\n",
        "cmDisplay = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = [\"1\", \"2\"])\n",
        "cmDisplay.plot()\n",
        "plt.show()\n",
        "\n",
        "#Calculate the scores\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "pre_train = precision_score(y_train, y_pred_train, average='macro')\n",
        "pre_test = precision_score(y_test, y_pred_test, average='macro')\n",
        "rec_train = recall_score(y_train, y_pred_train, average='macro')\n",
        "rec_test = recall_score(y_test, y_pred_test, average='macro')\n",
        "f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
        "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
        "\n",
        "#Print the scores\n",
        "print('Accuracy scores of Linear Discriminant Analysis are:',\n",
        " 'train: {:.2f}'.format(acc_train), 'and test:{:.2f}.'.format(acc_test))\n",
        "print('Precision scores of Linear Discriminant Analysis are:',\n",
        " 'train: {:.2f}'.format(pre_train), 'and test:{:.2f}.'.format(pre_test))\n",
        "print('Recall scores of Linear Discriminant Analysis are:',\n",
        " 'train: {:.2f}'.format(rec_train), 'and test:{:.2f}.'.format(rec_test))\n",
        "print('F1 scores of Linear Discriminant Analysis are:',\n",
        " 'train: {:.2f}'.format(f1_train), 'and test: {:.2f}.'.format(f1_test))"
      ],
      "metadata": {
        "id": "0eCJvNU-ffXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "5HWghpfFhqPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(class_weight='balanced')\n",
        "logreg.fit(X_train, y_train) #fit the model using the training data\n",
        "#now check for both train and test data, how well the model learned the patterns\n",
        "y_pred_train = logreg.predict(X_train)\n",
        "y_pred_test = logreg.predict(X_test)\n",
        "\n",
        "#Make confusion matrix to define tp, tn, fp, fn\n",
        "confMatrix = confusion_matrix(y_test, y_pred_test)\n",
        "cmDisplay = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = [\"1\", \"2\"])\n",
        "cmDisplay.plot()\n",
        "plt.show()\n",
        "\n",
        "#Calculate the scores\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "pre_train = precision_score(y_train, y_pred_train, average='macro')\n",
        "pre_test = precision_score(y_test, y_pred_test, average='macro')\n",
        "rec_train = recall_score(y_train, y_pred_train, average='macro')\n",
        "rec_test = recall_score(y_test, y_pred_test, average='macro')\n",
        "f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
        "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
        "\n",
        "#Print the scores\n",
        "print('Accuracy scores of LogisticRegression are:',\n",
        " 'train: {:.2f}'.format(acc_train), 'and test:{:.2f}.'.format(acc_test))\n",
        "print('Precision scores of LogisticRegression are:',\n",
        " 'train: {:.2f}'.format(pre_train), 'and test:{:.2f}.'.format(pre_test))\n",
        "print('Recall scores of LogisticRegression are:',\n",
        " 'train: {:.2f}'.format(rec_train), 'and test:{:.2f}.'.format(rec_test))\n",
        "print('F1 scores of  LogisticRegression are:',\n",
        " 'train: {:.2f}'.format(f1_train), 'and test: {:.2f}.'.format(f1_test))"
      ],
      "metadata": {
        "id": "nmKKycKShwGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes**"
      ],
      "metadata": {
        "id": "RLrW9xnoiBiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train) #fit the model using the training data\n",
        "#now check for both train and test data, how well the model learned the patterns\n",
        "y_pred_train = gnb.predict(X_train)\n",
        "y_pred_test = gnb.predict(X_test)\n",
        "\n",
        "#Make confusion matrix to define tp, tn, fp, fn\n",
        "confMatrix = confusion_matrix(y_test, y_pred_test)\n",
        "cmDisplay = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = [\"1\", \"2\"])\n",
        "cmDisplay.plot()\n",
        "plt.show()\n",
        "\n",
        "#Calculate the scores\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "pre_train = precision_score(y_train, y_pred_train, average='macro')\n",
        "pre_test = precision_score(y_test, y_pred_test, average='macro')\n",
        "rec_train = recall_score(y_train, y_pred_train, average='macro')\n",
        "rec_test = recall_score(y_test, y_pred_test, average='macro')\n",
        "f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
        "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
        "\n",
        "#Print the scores\n",
        "print('Accuracy scores of Naive Bayes classifier are:',\n",
        " 'train: {:.2f}'.format(acc_train), 'and test:{:.2f}.'.format(acc_test))\n",
        "print('Precision scores of Naive Bayes classifier are:',\n",
        " 'train: {:.2f}'.format(pre_train), 'and test:{:.2f}.'.format(pre_test))\n",
        "print('Recall scores of Naive Bayes classifier are:',\n",
        " 'train: {:.2f}'.format(rec_train), 'and test:{:.2f}.'.format(rec_test))\n",
        "print('F1 scores of Naive Bayes classifier are:',\n",
        " 'train: {:.2f}'.format(f1_train), 'and test: {:.2f}.'.format(f1_test))"
      ],
      "metadata": {
        "id": "JepEAtriiHG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine (SVM)**"
      ],
      "metadata": {
        "id": "0mk1ctTOidwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='sigmoid')\n",
        "svm.fit(X_train, y_train) #fit the model using the training data\n",
        "# now check for both train and test data, how well the model learned thepatterns\n",
        "y_pred_train = svm.predict(X_train)\n",
        "y_pred_test = svm.predict(X_test)\n",
        "\n",
        "\n",
        "#Make confusion matrix to define tp, tn, fp, fn\n",
        "confMatrix = confusion_matrix(y_test, y_pred_test)\n",
        "cmDisplay = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = [\"1\", \"2\"])\n",
        "cmDisplay.plot()\n",
        "plt.show()\n",
        "\n",
        "#Calculate the scores\n",
        "acc_train = accuracy_score(y_train, y_pred_train)\n",
        "acc_test = accuracy_score(y_test, y_pred_test)\n",
        "pre_train = precision_score(y_train, y_pred_train, average='macro')\n",
        "pre_test = precision_score(y_test, y_pred_test, average='macro')\n",
        "rec_train = recall_score(y_train, y_pred_train, average='macro')\n",
        "rec_test = recall_score(y_test, y_pred_test, average='macro')\n",
        "f1_train = f1_score(y_train, y_pred_train, average='macro')\n",
        "f1_test = f1_score(y_test, y_pred_test, average='macro')\n",
        "\n",
        "#Print the scores\n",
        "print('Accuracy scores of SVM classifier are:',\n",
        "'train: {:.2f}'.format(acc_train), 'and test:{:.2f}.'.format(acc_test))\n",
        "print('Precision scores of SVM classifier are:',\n",
        "'train: {:.2f}'.format(pre_train), 'and test:{:.2f}.'.format(pre_test))\n",
        "print('Recall scores of SVM classifier are:',\n",
        "'train: {:.2f}'.format(rec_train), 'and test:{:.2f}.'.format(rec_test))\n",
        "print('F1 scores of SVM classifier are:',\n",
        "'train: {:.2f}'.format(f1_train), 'and test: {:.2f}.'.format(f1_test))"
      ],
      "metadata": {
        "id": "CHS21WYxicWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Networks**"
      ],
      "metadata": {
        "id": "gnZWcOu9iKIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehpW9n3wc2c5"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "CustomModel = keras.models.Sequential()\n",
        "CustomModel.add(keras.layers.Dense(64, input_dim=X_train.shape[1],activation='relu'))\n",
        "#CustomModel.add(keras.layers.Dense(32, input_dim=X_train.shape[1],activation='relu'))\n",
        "#CustomModel.add(keras.layers.Dense(16, input_dim=new_X_train.shape[1],activation='relu'))\n",
        "#CustomModel.add(keras.layers.Dense(10, input_dim=new_X_train.shape[1],activation='relu'))\n",
        "CustomModel.add(keras.layers.Dense(3, activation='sigmoid'))\n",
        "\n",
        "# Display the architecture\n",
        "# Compile model using accuracy to measure model performance\n",
        "from keras.optimizers import SGD, Adam\n",
        "opt = Adam(learning_rate=0.01)\n",
        "CustomModel.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "CustomModel.fit(X_train, keras.utils.np_utils.to_categorical(y_train),epochs=300, batch_size = 100, verbose=False) #fit the model using the training data\n",
        "# Now check for both train and test data, how well the model learned the patterns\n",
        "y_pred_train = CustomModel.predict(X_train)\n",
        "classes_train=np.argmax(y_pred_train,axis=1)\n",
        "y_pred_test = CustomModel.predict(X_test)\n",
        "classes_test=np.argmax(y_pred_test,axis=1)\n",
        "\n",
        "# Make confusion matrix to define tp, tn, fp, fn\n",
        "confMatrix = confusion_matrix(y_test, classes_test)\n",
        "cmDisplay = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = [\"1\", \"2\"])\n",
        "cmDisplay.plot()\n",
        "plt.show()\n",
        "\n",
        "# Calculate the scores\n",
        "acc_train = accuracy_score(y_train, classes_train)\n",
        "acc_test = accuracy_score(y_test, classes_test)\n",
        "pre_train = precision_score(y_train, classes_train, average='macro')\n",
        "pre_test = precision_score(y_test, classes_test, average='macro')\n",
        "rec_train = recall_score(y_train, classes_train, average='macro')\n",
        "rec_test = recall_score(y_test, classes_test, average='macro')\n",
        "f1_train = f1_score(y_train, classes_train, average='macro')\n",
        "f1_test = f1_score(y_test, classes_test, average='macro')\n",
        "\n",
        "#Print the scores\n",
        "print('Accuracy scores of Neural Networks are:',\n",
        "'train: {:.2f}'.format(acc_train), 'and test:{:.2f}.'.format(acc_test))\n",
        "print('Precision scores of Neural Networks are:',\n",
        "'train: {:.2f}'.format(pre_train), 'and test:{:.2f}.'.format(pre_test))\n",
        "print('Recall scores of Neural Networks are:',\n",
        "'train: {:.2f}'.format(rec_train), 'and test:{:.2f}.'.format(rec_test))\n",
        "print('F1 scores of Neural Networks are:',\n",
        "'train: {:.2f}'.format(f1_train), 'and test: {:.2f}.'.format(f1_test))\n"
      ]
    }
  ]
}